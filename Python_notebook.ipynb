import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# --- Preprocessing --- #
file_path = "/home/ubuntu/online_retail_data/online_retail_II.xlsx"
df_2009_2010 = pd.read_excel(file_path, sheet_name="Year 2009-2010")
df_2010_2011 = pd.read_excel(file_path, sheet_name="Year 2010-2011")
df = pd.concat([df_2009_2010, df_2010_2011], ignore_index=True)

# Drop rows with missing CustomerID
df.dropna(subset=["Customer ID"], inplace=True)

# Convert InvoiceDate to datetime
df["InvoiceDate"] = pd.to_datetime(df["InvoiceDate"])

# Calculate TotalPrice
df["TotalPrice"] = df["Quantity"] * df["Price"]

# Save preprocessed data to CSV
df.to_csv("preprocessed_online_retail.csv", index=False)

print("Data preprocessing complete. Saved to preprocessed_online_retail.csv")

# --- Feature Engineering and Model Training --- #
# Load preprocessed data
df = pd.read_csv("preprocessed_online_retail.csv", parse_dates=["InvoiceDate"])

# Convert Customer ID to int
df["Customer ID"] = df["Customer ID"].astype(int)

# Feature Engineering for RFM (Recency, Frequency, Monetary)
# Recency: Days since last purchase
# Frequency: Number of purchases
# Monetary: Total spend

# Get the latest date in the dataset for recency calculation
latest_date = df["InvoiceDate"].max()

rfm = df.groupby("Customer ID").agg({
    "InvoiceDate": lambda date: (latest_date - date.max()).days,
    "Invoice": lambda num: num.nunique(),
    "TotalPrice": lambda price: price.sum()
})

rfm.columns = ["Recency", "Frequency", "Monetary"]

# Calculate Average Order Value (AOV)
rfm["AOV"] = rfm["Monetary"] / rfm["Frequency"]

# Define CLTV as Monetary for simplicity in this example
# In a real scenario, more sophisticated CLTV models would be used
rfm["CLTV"] = rfm["Monetary"]

# Prepare data for modeling
X = rfm[["Recency", "Frequency", "Monetary", "AOV"]]
y = rfm["CLTV"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train XGBoost Regressor model
model = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")

# Save the trained model
joblib.dump(model, "cltv_model.joblib")

# Save RFM data with CLTV predictions (for segmentation)
rfm["Predicted_CLTV"] = model.predict(X)
rfm.to_csv("Final_LTV_prediction.csv")

print("Model training and evaluation complete. Model saved as cltv_model.joblib and RFM data with predictions saved as Final_LTV_prediction.csv")

# --- Visualizations --- #
# Distribution of Recency, Frequency, Monetary
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
sns.histplot(rfm["Recency"], bins=50)
plt.title("Recency Distribution")

plt.subplot(1, 3, 2)
sns.histplot(rfm["Frequency"], bins=50)
plt.title("Frequency Distribution")

plt.subplot(1, 3, 3)
sns.histplot(rfm["Monetary"], bins=50)
plt.title("Monetary Distribution")
plt.tight_layout()
plt.savefig("rfm_distributions.png")
plt.close()

# Scatter plot of Predicted vs Actual CLTV
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.3)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "--r", linewidth=2)
plt.xlabel("Actual CLTV")
plt.ylabel("Predicted CLTV")
plt.title("Actual vs Predicted CLTV")
plt.savefig("actual_vs_predicted_cltv.png")
plt.close()

print("Visualizations generated: rfm_distributions.png and actual_vs_predicted_cltv.png")


